# ğŸ›¡ï¸ GuardPrompt - Prompt Injection and Data Leakage Guard using LLMs

This local Gradio app demonstrates prompt-injection and data-leakage mitigation using:
- **Guard LLM:** `meta-llama/Meta-Llama-3-1B-Instruct`
- **Response LLM:** `meta-llama/Meta-Llama-3-3B-Instruct`

## ğŸš€ Run Locally on macOS M1/M2/M3
```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python app.py
